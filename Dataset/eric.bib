@misc{Holloway2020,
abstract = {The legal and ethical use of Big Data and Learning Analytics in academic libraries has been widely debated. Analyzing large data sets has tremendous potential for libraries to implement changes that help students and prove the library's value to the university. The librarian's role in safeguarding patron privacy in a university setting where learning analytics of Big Data is becoming the norm is still in the formative phase. This is a literature review on the ethical use of Big Data in universities and librarians' ethical commitment to patrons. Student profiling, legislative response to technology, and ownership of information gathered are discussed.},
author = {Holloway, Kristine},
booktitle = {Journal of Electronic Resources Librarianship},
language = {English},
number = {4},
pages = {276--285},
title = {{Big Data and Learning Analytics in Higher Education: Legal and Ethical Considerations}},
volume = {32},
year = {2020}
}
@misc{Fournier,
abstract = {This paper will present current work on various frameworks that are aimed at guiding the research, development, and evaluation efforts around Massive Open Online Courses (MOOCs). Initiatives and activities, including current work by the National Research Council (NRC) in the context of Learning and Performance Support Systems and MOOCs, will be presented along with outstanding challenges and issues to be addressed in the near future. Findings from case studies of Personal Learning Environments (PLEs) and MOOCs will be presented which suggest that learning experiences are impacted by much more than tools and technologies. There is the potential for an enormous palette of possibilities for creating effective, meaningful, and successful learning experiences, as well as many important issues and challenges to address. Recommendations coming of out of recent cMOOC surveys and forums will highlight participant focused and learner driven processes along with a changing notion of time and space in online learning environments. The paper also unveils current and future areas of research and development in a new Learning and Performance Support System (LPSS) program at NRC, including learning analytics, big data, and educational data mining, as well as ethics and privacy issues in networked environments and the use of personal learning data to feed into the research and development process.},
author = {Fournier, H{\'{e}}l{\`{e}}ne and Kop, Rita},
booktitle = {International Journal on E-Learning},
language = {English},
number = {3},
pages = {289--304},
title = {{MOOC Learning Experience Design: Issues and Challenges}},
volume = {14}
}
@misc{Owen,
abstract = {As a digital learning medium, serious games can be powerful, immersive educational vehicles and provide large data streams for understanding player behavior. Educational data mining and learning analytics can effectively leverage big data in this context to heighten insight into student trajectories and behavior profiles. In application of these methods, distilling event-stream data down to a set of salient features for analysis (i.e. feature engineering) is a vital element of robust modeling. This paper presents a process for systematic game-based feature engineering to optimize insight into player behavior: the IDEFA framework (Integrated Design of Event-stream Features for Analysis). IDEFA aligns game design and data collection for high-resolution feature engineering, honed through critical, iterative interplay with analysis. Building on recent research in game-based data mining, we empirically investigate IDEFA application in serious games. Results show that behavioral models which used a full feature set produced more meaningful results than those with no feature engineering, with greater insight into impactful learning interactions, and play trajectories characterizing groups of players. This discovery of emergent player behavior is fueled by the data framework, resultant base data stream, and rigorous feature creation process put forward in IDEFA--integrating iterative design, feature engineering, and analysis for optimal insight into serious play.},
author = {Owen, V Elizabeth and Baker, Ryan S},
booktitle = {Technology, Knowledge and Learning},
language = {English},
number = {2},
pages = {225--250},
title = {{Fueling Prediction of Player Decisions: Foundations of Feature Engineering for Optimized Behavior Modeling in Serious Games}},
volume = {25}
}
@misc{Hall2016,
abstract = {Neoliberalism is a global pedagogical project aimed at the dispossession of free time so that all of life becomes productive, and education is a central institutional means for its realisation. This project aims at marketising all of social life, so that life becomes predicated upon the extraction of value. In part the deployment of technologies, technical services, and techniques enables education to be co-opted as an institutional means for production and control. This occurs inside both formal and informal educational institutions and spaces, like universities and Massive Open On-line Courses, as one mechanism to offset the tendency for the rate of profit to fall and to re-establish accumulation. This pedagogic project also tends to recalibrate and enclose the roles of staff and students as entrepreneurial subjects, whose labour is enabled through technology. This is achieved through learning analytics, big data, mobility and flexibility of provision, and so on. At issue is the extent to which this neoliberal project can be resisted or refused, and alternatives described. This article will analyse the relationships between technology, pedagogy, and the critical subject in the neoliberal University, in order to argue for the use of technology inside a co-operative pedagogy of struggle. This demands that we ask what education is, before we ask what it is for, or the place of technology-enhanced learning in the university. The article considers whether it is possible to uncover ways in which education might be used for co-operation rather than competition, and what technology-enhanced co-operative education might look like?},
author = {Hall, Richard},
booktitle = {Interactive Learning Environments},
language = {English},
number = {5},
pages = {1004--1015},
title = {{Technology-Enhanced Learning and Co-Operative Practice against the Neoliberal University}},
volume = {24},
year = {2016}
}
@misc{Rienties2018,
abstract = {Language education has a rich history of research and scholarship focusing on the effectiveness of learning activities and the impact these have on student behaviour and outcomes. One of the basic assumptions in foreign language pedagogy and CALL in particular is that learners want to be able to communicate effectively with native speakers of their chosen language. Combining principles of learning analytics and Big Data with learning design, this study used a student activity based taxonomy adopted by the Open University UK to inform module design. The learning designs of four introductory and intermediary language education modules and online engagement of 2111 learners were contrasted using weekly learning design data. In this study, we aimed to explore how learning design decisions made by language teachers influenced students' engagement in the VLE. Using fixed effect models, our findings indicated that 55{\%} of variance of weekly online engagement in these four modules was explained by the way language teachers designed weekly learning design activities. Our learning analytics study highlights the potential affordances for CALL researchers to use the power of learning design and big data to explore and understand the complexities and dynamics of language learning for students and teachers.},
author = {Rienties, Bart and Lewis, Tim and McFarlane, Ruth and Nguyen, Quan and Toetenel, Lisette},
booktitle = {Computer Assisted Language Learning},
language = {English},
number = {3},
pages = {273--293},
title = {{Analytics in Online and Offline Language Learning Environments: The Role of Learning Design to Understand Student Online Engagement}},
volume = {31},
year = {2018}
}
@misc{Czerkawski,
abstract = {While student data systems are nothing new and most educators have been dealing with student data for many years, learning analytics has emerged as a new concept to capture educational big data. Learning analytics is about better understanding of the learning and teaching process and interpreting student data to improve their success and learning experiences. This paper provides an overview to learning analytics in higher education and more specifically, in e-learning. It also explores some of the issues around learning analytics.},
author = {Czerkawski, Betul C},
booktitle = {Online Journal of Distance Learning Administration},
language = {English},
number = {2},
title = {{When Learning Analytics Meets E-Learning}},
volume = {18}
}
@misc{Reidenberg,
abstract = {Education, Big Data, and student privacy are a combustible mix. The improvement of education and the protection of student privacy are key societal values. Big Data and Learning Analytics offer the promise of unlocking insights to improving education through large-scale empirical analysis of data generated from student information and student interactions with educational technology tools. This article explores how learning technologies also create ethical tensions between privacy and the use of Big Data for educational improvement. We argue for the need to demonstrate the efficacy of learning systems while respecting privacy and how to build accountability and oversight into learning technologies. We conclude with policy recommendations to achieve these goals.},
author = {Reidenberg, Joel R and Schaub, Florian},
booktitle = {Theory and Research in Education},
language = {English},
number = {3},
pages = {263--279},
title = {{Achieving Big Data Privacy in Education}},
volume = {16}
}
@misc{Lu2018,
abstract = {Blended learning combines online digital resources with traditional classroom activities and enables students to attain higher learning performance through well-defined interactive strategies involving online and traditional learning activities. Learning analytics is a conceptual framework and is a part of our Precision education used to analyze and predict students' performance and provide timely interventions based on student learning profiles. This study applied learning analytics and educational big data approaches for the early prediction of students' final academic performance in a blended Calculus course. Real data with 21 variables were collected from the proposed course, consisting of video-viewing behaviors, out-of-class practice behaviors, homework and quiz scores, and after-school tutoring. This study applied principal component regression to predict students' final academic performance. The experimental results show that students' final academic performance could be predicted when only one-third of the semester had elapsed. In addition, we identified seven critical factors that affect students' academic performance, consisting of four online factors and three traditional factors. The results showed that the blended data set combining online and traditional critical factors had the highest predictive performance.},
author = {Lu, Owen H T and Huang, Anna Y Q and Huang, Jeff C H and Lin, Albert J Q and Ogata, Hiroaki and Yang, Stephen J H},
booktitle = {Educational Technology {\&} Society},
language = {English},
number = {2},
pages = {220--232},
title = {{Applying Learning Analytics for the Early Prediction of Students' Academic Performance in Blended Learning}},
volume = {21},
year = {2018}
}
@misc{Thompson2017,
abstract = {Big Data and Learning Analytics' promise to revolutionise educational institutions, endeavours, and actions through more and better data is now compelling. Multiple, and continually updating, data sets produce a new sense of "personalised learning." A crucial attribute of the datafication, and subsequent profiling, of learner behaviour and engagement is the continual modification of the learning environment to induce greater levels of investment on the parts of each learner. The assumption is that more and better data, gathered faster and fed into ever-updating algorithms, provide more complete tools to understand, and therefore improve, learning experiences through adaptive personalisation. The argument in this paper is that Learning Personalisation names a new logistics of investment as the common "sense" of the school, in which disciplinary education is 'both disappearing and giving way to frightful continual training, to continual monitoring'.},
author = {Thompson, Greg and Cook, Ian},
booktitle = {Discourse: Studies in the Cultural Politics of Education},
language = {English},
number = {5},
pages = {740--754},
title = {{The Logic of Data-Sense: Thinking through Learning Personalisation}},
volume = {38},
year = {2017}
}
@misc{Strang,
abstract = {This mixed-method study focuses on online learning analytics, a research area of importance. Several important student attributes and their online activities are examined to identify what seems to work best to predict higher grades. The purpose is to explore the relationships between student grade and key learning engagement factors using a large sample from an online undergraduate business course at an accredited American university (n = 228). Recent studies have discounted the ability to predict student learning outcomes from big data analytics but a few significant indicators have been found by some researchers. Current studies tend to use quantitative factors in learning analytics to forecast outcomes. This study extends that work by testing the common quantitative predictors of learning outcome, but qualitative data is also examined to triangulate the evidence. Pre and post testing of information technology understanding is done at the beginning of the course. First quantitative data is collected, and depending on the hypothesis test results, qualitative data is collected and analyzed with text analytics to uncover patterns. Moodle engagement analytics indicators are tested as predictors in the model. Data is also taken from the Moodle system logs. Qualitative data is collected from student reflection essays. The result was a significant General Linear Model with four online interaction predictors that captured 77.5{\%} of grade variance in an undergraduate business course.},
author = {Strang, Kenneth David},
booktitle = {Education and Information Technologies},
language = {English},
number = {3},
pages = {917--937},
title = {{Beyond Engagement Analytics: Which Online Mixed-Data Factors Predict Student Learning Outcomes?}},
volume = {22}
}
@misc{Chaurasia2018,
abstract = {Purpose: Although big data analytics (BDA) have great benefits for higher education institutions (HEIs), due to lack of sufficient evidence on how BDA investment can pay off, it is tough for HEIs practitioners to realize value from such adoption. The purpose of this paper is to propose a big data academic and learning analytics enabled business value model to explain BDA potential benefits and business value which can be obtained by developing such analytics capabilities in HEIs. Design/methodology/approach: The study examined 47 case descriptions from 26 HEIs to investigate the causal association between the BDA current and potential benefits and business value creation path for big data academic and learning analytics success in HEIs. Findings: The pressure of compliance with all legal and regulatory requirements and competition had pushed HEIs hard to adopt BDA tools. However, the study found out that application of risk and security and predictive analytics to higher education fields is still in its infancy. Using this theoretical model, the results provide new insights to higher education administrators on ways to create BDA capabilities for HEIs transformation and suggest an empirical foundation that can lead to more thorough analysis of BDA implementation. Originality/value: A distinctive theoretical contribution of this study is its conceptualization of understanding business value from BDA in the typical setting of higher education. The study provides HEIs with an all-inclusive understanding of BDA and gives insights on how it helps to transform HEIs. The new perspectives associated with the big data academic and learning analytics enabled business value model will contribute to future research in this area.},
author = {Chaurasia, Sushil S and Kodwani, Devendra and Lachhwani, Hitendra and Ketkar, Manisha Avadhut},
booktitle = {International Journal of Educational Management},
language = {English},
number = {6},
pages = {1099--1117},
title = {{Big Data Academic and Learning Analytics: Connecting the Dots for Academic Excellence in Higher Education}},
volume = {32},
year = {2018}
}
@misc{Korkmaz2019,
abstract = {The purpose of this review is to investigate the trends in the body of research on machine learning in educational technologies, published between 2007 and 2017. The criteria for article selection were as follows: (1) study on machine learning in educational/learning technologies, (2) published between 2007-2017, (3) published in a peer-reviewed outlet, and (4) an empirical study, literature review, or meta-analysis. Eighty-nine articles were chosen, after the first round of the article selection process. Through a second look at the articles, fifteen articles that did not match the criteria were eliminated. After the close examination of the seventy-four articles, certain demographical and thematic trends emerged. The top contributors to the body of research were Taiwan and the United States while the most productive year was 2017. The most utilized machine learning methods were vectors and decision trees. Commonly researched areas, on the other hand, were automation, cognitive process assessment, prediction, intelligent tutoring systems, and opportunities and challenges in the use of big data {\&} learning analytics. Recommendations for future research focus on expanding geographical diversity, incorporating Bayesian and fuzzy logic methods more in educational machine learning work.},
author = {Korkmaz, Ceren and Correia, Ana-Paula},
booktitle = {Educational Media International},
language = {English},
number = {3},
pages = {250--267},
title = {{A Review of Research on Machine Learning in Educational Technology}},
volume = {56},
year = {2019}
}
@misc{Williamson,
abstract = {"Education data science" is an emerging methodological field which possesses the algorithm-driven technologies required to generate insights and knowledge from educational big data. This article consists of an analysis of the Lytics Lab, Stanford University's laboratory for research and development in learning analytics, and the Center for Digital Data, Analytics and Adaptive Learning, a big data research centre of the commercial education company Pearson. These institutions are becoming methodological gatekeepers with the capacity to conduct new forms of educational research using big data and algorithmic data science methods. The central argument is that as educational data science has migrated from the academic lab to the commercial sector, ownership of the means to produce educational data analyses has become concentrated in the activities of for-profit companies. As a consequence, new theories of learning are being built-in to the tools they provide, in the shape of algorithm-driven technologies of personalization, which can be sold to schools and universities. The paper addresses two themes of this special issue: (1) how education is to be theorized in relation to algorithmic methods and data scientific epistemologies and (2) how the political economy of education is shifting as knowledge production becomes concentrated in data-driven commercial organizations.},
author = {Williamson, Ben},
booktitle = {E-Learning and Digital Media},
language = {English},
number = {3},
pages = {105--122},
title = {{Who Owns Educational Theory? Big Data, Algorithms and the Expert Power of Education Data Science}},
volume = {14}
}
@misc{Edwards2016,
abstract = {In a wide range of fields, professional practice is being transformed by the increasing influence of digital analytics: the massive volumes of big data, and software algorithms that are collecting, comparing and calculating that data to make predictions and even decisions. Researchers in a number of social sciences have been calling attention to the far-reaching and accelerating consequences of these forces, claiming that many professionals, researchers, policy-makers and the public are just beginning to realise the enormous potentials and challenges these analytics are producing. Yet, outside of particular areas of research and practice, such as learning analytics, there has been little discussion of this to date in the broader education literature. This article aims to set out some key issues particularly relevant to the understandings of professional practice, knowledge and learning posed by the linkages of big data and software code. It begins by outlining definitions, forms and examples of these analytics, their potentialities and some of the hidden impact, and then presents issues for researchers and educators. It seeks to contribute to and extend debates taking place in certain quarters to a broader professional education and work audience.},
author = {Edwards, Richard and Fenwick, Tara},
booktitle = {Studies in Continuing Education},
language = {English},
number = {2},
pages = {213--227},
title = {{Digital Analytics in Professional Work and Learning}},
volume = {38},
year = {2016}
}
@misc{Macfadyen,
abstract = {In the new era of big educational data, learning analytics (LA) offer the possibility of implementing real-time assessment and feedback systems and processes at scale that are focused on improvement of learning, development of self-regulated learning skills, and student success. However, to realize this promise, the necessary shifts in the culture, technological infrastructure, and teaching practices of higher education, from assessment-for-accountability to assessment-for-learning, cannot be achieved through piecemeal implementation of new tools. We propose here that the challenge of successful institutional change for learning analytics implementation is a wicked problem that calls for new adaptive forms of leadership, collaboration, policy development and strategic planning. Higher education institutions are best viewed as complex systems underpinned by policy, and we introduce two policy and planning frameworks developed for complex systems that may offer institutional teams practical guidance in their project of optimizing their educational systems with learning analytics.},
author = {Macfadyen, Leah P and Dawson, Shane and Pardo, Abelardo and Ga{\v{s}}evic, Dragan},
booktitle = {Research {\&} Practice in Assessment},
language = {English},
pages = {17--28},
title = {{Embracing Big Data in Complex Educational Systems: The Learning Analytics Imperative and the Policy Challenge}},
volume = {9}
}
@misc{Doleck,
abstract = {Large swaths of data are readily available in various fields, and education is no exception. In tandem, the impetus to derive meaningful insights from data gains urgency. Recent advances in deep learning, particularly in the area of voice and image recognition and so-called complete knowledge games like chess, go, and StarCraft, have resulted in a flurry of research. Using two educational datasets, we explore the utility and applicability of "deep learning" for educational data mining and learning analytics. We compare the predictive accuracy of popular deep learning frameworks/libraries, including, Keras, Theano, Tensorflow, fast.ai, and Pytorch. Experimental results reveal that performance, as assessed by predictive accuracy, varies depending on the optimizer used. Further, findings from additional experiments by tuning network parameters yield similar results. Moreover, we find that deep learning displays comparable performance to other machine learning algorithms such as support vector machines, k-nearest neighbors, naive Bayes classifier, and logistic regression. We argue that statistical learning techniques should be selected to maximize interpretability and should contribute to our understanding of educational and learning phenomena; hence, in most cases, educational data mining and learning analytics researchers should aim for explanation over prediction.},
author = {Doleck, Tenzin and Lemay, David John and Basnet, Ram B and Bazelais, Paul},
booktitle = {Education and Information Technologies},
language = {English},
number = {3},
pages = {1951--1963},
title = {{Predictive Analytics in Education: A Comparison of Deep Learning Frameworks}},
volume = {25}
}
@misc{Liu,
abstract = {Nowadays, Massive Open Online Courses (MOOCs) have obtained a rapid development and drawn much attention from the areas of learning analytics and artificial intelligence. There are lots of unstructured data being generated in online reviews area. The learning behavioral data become more and more diverse, and they prompt the emergence of big data in education. To mine useful information from these data, we need to use educational data mining and learning analysis technique to study the learning feelings and discussed topics among learners. This paper aims to mine and analyze topic information hidden in the unstructured reviews data in MOOCs; a novel author topic model based on an unsupervised learning idea is proposed to extract learning topics for each learner. According to the experimental results, we will analyze and focus on interests of learners, which facilitates further personalized course recommendation and improves the quality of online courses.},
author = {Liu, Sanya and Ni, Cheng and Liu, Zhi and Peng, Xian and Cheng, Hercy N H},
booktitle = {International Journal of Distance Education Technologies},
language = {English},
number = {3},
pages = {1--14},
title = {{Mining Individual Learning Topics in Course Reviews Based on Author Topic Model}},
volume = {15}
}
@misc{Miller2015,
abstract = {Learning objects (LOs) are important online resources for both learners and instructors and usage for LOs is growing. Automatic LO tracking collects large amounts of metadata about individual students as well as data aggregated across courses, learning objects, and other demographic characteristics (e.g. gender). The challenge becomes identifying which of the many variables derived from tracked data are useful for predicting student learning. This challenge has prompted considerable research in the field of educational data mining and learning analytics. This work advances such research in four ways. First, we bring together two approaches for finding salient variables from separate research areas: hierarchical linear modeling (HLM) from education and Lasso feature selection from computer science. Second, we show that these two approaches have complimentary and synergistic results with some variables considers salient by both and others salient by only one. Third, and most importantly, we demonstrate the benefits of a combined approach that considers a variable salient when either HLM or Lasso consider that variable salient. This combined approach both improves model predictive accuracy and finds additional variables considered salient in previous datasets on student learning. Lastly, we use the results to provide insights into the salient variables to the learning outcome in undergraduate CS education. Overall, this work suggests a combined approach that improves the identification of salient variables in big data and also improves the design of LO tracking systems for learning management systems.},
author = {Miller, L Dee and Soh, Leen-Kiat and Samal, Ashok and Kupzyk, Kevin and Nugent, Gwen},
booktitle = {Journal of Educational Data Mining},
language = {English},
number = {3},
pages = {117--150},
title = {{A Comparison of Educational Statistics and Data Mining Approaches to Identify Characteristics That Impact Online Learning}},
volume = {7},
year = {2015}
}
@misc{Flanagan,
abstract = {In recent years, learning analytics has become a hot topic with many institutes deploying learning management systems and learning analytics tools. In this paper, we introduce learning analytics platforms that have been established in two top national Japanese universities. These initiatives are part of a broader research project into creating wide-reaching learning analytics frameworks. The aim of the project is to support education and learning through research into educational big data accumulated on these platforms. We also discuss the future direction of our research into learning analytics platforms. This includes introducing a model in which learning analytics tools and the results of research can be shared between different education institutes.},
author = {Flanagan, Brendan and Ogata, Hiroaki},
booktitle = {Knowledge Management {\&} E-Learning},
language = {English},
number = {4},
pages = {469--484},
title = {{Learning Analytics Platform in Higher Education in Japan}},
volume = {10}
}
@misc{Charitopoulos,
abstract = {The aim of this paper is to survey recent research publications that use Soft Computing methods to answer education-related problems based on the analysis of educational data 'mined' mainly from interactive/e-learning systems. Such systems are known to generate and store large volumes of data that can be exploited to assess the learner, the system and the quality of the interaction between them. Educational Data Mining (EDM) and Learning Analytics (LA) are two distinct and yet closely related research areas that focus on this data aiming to address open education-related questions or issues. Besides 'classic' data analysis methods such as clustering, classification, identification or regression/analysis of variances, soft computing methods are often employed by EDM and LA researchers to achieve their various tasks. Their very nature as iterative optimization algorithms that avoid the exhaustive search of the solutions space and go for possibly suboptimal solutions yet at realistic time and effort, along with their heavy reliance on rich data sets for training, make soft computing methods ideal tools for the EDM or LA type of problems. Decision trees, random forests, artificial neural networks, fuzzy logic, support vector machines and genetic/evolutionary algorithms are a few examples of soft computing approaches that, given enough data, can successfully deal with uncertainty, qualitatively stated problems and incomplete, imprecise or even contradictory data sets--features that the field of education shares with all humanities/social sciences fields. The present review focuses, therefore, on recent EDM and LA research that employs at least one soft computing method, and aims to identify (i) the major "education problems/issues" addressed and, consequently, "research goals/objectives" set, (ii) the "learning contexts/settings" within which relevant research and educational interventions take place, (iii) the relation between "classic and soft computing methods" employed to solve specific problems/issues, and (iv) the means of dissemination ("publication journals") of the relevant research results. Selection and analysis of a body of 300 journal publications reveals that top research questions in education today seeking answers through soft computing methods refer directly to the issue of "quality"--a critical issue given the currently dominant educational/pedagogical models that favor e-learning or computer- or technology-mediated learning contexts. Moreover, results identify the most frequently used methods and tools within EDM/LA research and, comparatively, within their soft computing subsets, along with the major journals relevant research is being published worldwide. Weaknesses and issues that need further attention in order to fully exploit the benefits of research results to improve both the learning experience and the learning outcomes are discussed in the conclusions.},
author = {Charitopoulos, Angelos and Rangoussi, Maria and Koulouriotis, Dimitrios},
booktitle = {International Journal of Artificial Intelligence in Education},
language = {English},
number = {3},
pages = {371--430},
title = {{On the Use of Soft Computing Methods in Educational Data Mining and Learning Analytics Research: A Review of Years 2010-2018}},
volume = {30}
}
@misc{Christopoulos,
abstract = {While virtual reality has attracted educators' interest by providing new opportunities to the learning process and assessment in different science, technology, engineering and mathematics (STEM) subjects, the results from previous studies indicate that there is still much work to be done when large data collection and analysis is considered. At the same time, learning analytics emerged with the promise to revolutionise the traditional practices by introducing new ways to systematically assess and improve the effectiveness of instruction. However, the collection of 'big' educational data is mostly associated with web-based platforms (i.e., learning management systems) as they offer direct access to students' data with minimal effort. Thence, in the context of this work, we present a four-dimensional theoretical framework for virtual reality-supported instruction and propose a set of structural elements that can be utilised in conjunction with a learning analytics prototype system. The outcomes of this work are expected to support practitioners on how to maximise the potential of their interventions and provide further inspiration for the development of new ones.},
author = {Christopoulos, Athanasios and Pellas, Nikolaos and Laakso, Mikko-Jussi},
booktitle = {Education Sciences},
title = {{A Learning Analytics Theoretical Framework for STEM Education Virtual Reality Applications}},
volume = {10}
}
@misc{Kelly2017,
abstract = {Purpose: The purpose of this paper is to demonstrate the utility of combining event-centred and variable-centred approaches when analysing big data for higher education institutions. It uses a large, university-wide data set to demonstrate the methodology for this analysis by using the case study method. It presents empirical findings about relationships between student behaviours in a learning management system (LMS) and the learning outcomes of students, and further explores these findings using process modelling techniques. Design/methodology/approach: The paper describes a two-year study in a Chilean university, using big data from a LMS and from the central university database of student results and demographics. Descriptive statistics of LMS use in different years presents an overall picture of student use of the system. Process mining is described as an event-centred approach to give a deeper level of understanding of these findings. Findings: The study found evidence to support the idea that instructors do not strongly influence student use of an LMS. It replicates existing studies to show that higher-performing students use an LMS differently from the lower-performing students. It shows the value of combining variable- and event-centred approaches to learning analytics. Research limitations/implications: The study is limited by its institutional context, its two-year time frame and by its exploratory mode of investigation to create a case study. Practical implications: The paper is useful for institutions in developing a methodology for using big data from a LMS to make use of event-centred approaches. Originality/value: The paper is valuable in replicating and extending recent studies using event-centred approaches to analysis of learning data. The study here is on a larger scale than the existing studies (using a university-wide data set), in a novel context (Latin America), that provides a clear description for how and why the methodology should inform institutional approaches.},
author = {Kelly, Nick and Montenegro, Maximiliano and Gonzalez, Carlos and Clasing, Paula and Sandoval, Augusto and Jara, Magdalena and Saurina, Elvira and Alarc{\'{o}}n, Rosa},
booktitle = {International Journal of Information and Learning Technology},
language = {English},
number = {1},
pages = {63--78},
title = {{Combining Event- and Variable-Centred Approaches to Institution-Facing Learning Analytics at the Unit of Study Level}},
volume = {34},
year = {2017}
}
@misc{Wang,
abstract = {Against the backdrop of the ever-increasing influx of big data, this article examines the opportunities and concerns over big data in education. Specifically, this article first introduces big data, followed by delineating the potential opportunities of using big data in education in two areas: learning analytics and educational policy. Then, the concerns over data security, privacy protection, and ethical boundaries of accessing personal digital data are discussed. The article concludes with an invitation to education practitioners, policymakers, and researchers to advance our understanding of big data and better serve students in the digital era.},
author = {Wang, Yinying},
booktitle = {TechTrends: Linking Research and Practice to Improve Learning},
language = {English},
number = {4},
pages = {381--384},
title = {{Big Opportunities and Big Concerns of Big Data in Education}},
volume = {60}
}
@misc{Martin2013,
abstract = {The learning sciences community's interest in learning analytics (LA) has been growing steadily over the past several years. Three recent symposia on the theme (at the American Educational Research Association 2011 and 2012 annual conferences, and the International Conference of the Learning Sciences 2012), organized by Paulo Blikstein, led to the meeting of learning scientists working in this area and ultimately generated the proposal for this special issue. In the two years that the authors have worked on putting together this special issue, the task of writing an introduction has become both much simpler and significantly more difficult. On the one hand, many of the trends that are driving the increasing attention to LA--big data, the Cloud--have become so prominent that the authors can count on readers to have some familiarity with them. Thus, the authors of this article do not need to start at the beginning of the discussion of LA for the "Journal of the Learning Sciences" ("JLS") audience. On the other hand, the scope of the field and the potential applications have grown tremendously in this short time. The result is that, if anything, the authors feel that they have fallen further behind. Although the educational data mining and LA communities have produced a steady stream of interesting results, work in education has far to go in order to reap the benefits for student learning that, say, businesses have reaped in advertising. The purpose of this special issue is to provide a focal point for researchers in learning sciences to understand and discuss the potential of LA. It is the hope of these authors that the special issue can introduce the community to the possibilities of LA and frame discussions of the future role of LA in the learning sciences.},
author = {Martin, Taylor and Sherin, Bruce},
booktitle = {Journal of the Learning Sciences},
language = {English},
number = {4},
pages = {511--520},
title = {{Learning Analytics and Computational Techniques for Detecting and Evaluating Patterns in Learning: An Introduction to the Special Issue}},
volume = {22},
year = {2013}
}
@misc{Bulut2019,
abstract = {Educational data mining (EDM) has been a rapidly growing research field over the last decade and enabled researchers to discover patterns and trends in education with more sophisticated methods. EDM offers promising solutions to complex educational problems. Given the rapid increase in the availability of big data in education and software programs to analyze big data, the demand for user-friendly, free software programs to implement EDM methods also continues to increase. The R programming language has become a popular environment for data mining due to its availability and flexibility. The "rattle" package in R contains a set of functions to implement data mining with a graphical user interface. This study demonstrates three widely used data mining algorithms (classification and regression tree, random forest, and support vector machine) in EDM using real data from the 2015 administration of the Programme for International Student Assessment (PISA). First, a brief introduction to EDM is provided along with the description of the selected data mining algorithms. Then, how to perform data mining analysis using the "rattle's" graphical user interface is demonstrated. The study concludes by comparing the results of the selected data mining algorithms and highlighting how those algorithms can be utilized in the context of educational research.},
author = {Bulut, Okan and Yavuz, Hatice Cigdem},
booktitle = {International Journal of Assessment Tools in Education},
language = {English},
number = {5},
pages = {20--36},
title = {{Educational Data Mining: A Tutorial for the "Rattle" Package in R}},
volume = {6},
year = {2019}
}
@misc{Bronnimann,
abstract = {In this article we report on the findings of a project funded by the Australian Office for Learning and Teaching and entitled "Learning Analytics: Assisting Universities with Student Retention." While this project was primarily focused on retention as a potential outcome of learning analytics, its application could be related to the broader concept of student success. Student success allows for a focus on pedagogy and the use of learning analytics for the improvement of learning and teaching with a firm scholarly evidence base. The data gathered for the project provide the background for a discussion about the potential of learning analytics to inform the practice of the Scholarship of Teaching and Learning. A case study demonstrates the potential of this approach. Overall, clear pedagogical questions are important in the application of learning analytics to the Scholarship of Teaching and Learning, and we suggest potential ways to explore pedagogical questions with big data methods.},
author = {Bronnimann, Jurg and West, Deborah and Huijser, Henk and Heath, David},
booktitle = {Innovative Higher Education},
language = {English},
number = {5},
pages = {353--367},
title = {{Applying Learning Analytics to the Scholarship of Teaching and Learning}},
volume = {43}
}
@misc{VillanuevaManjarres2018,
abstract = {Educational Data Mining is an emerging discipline which seeks to develop methods to explore large amounts of data from educational settings, in order to understand students' behavior, interests and results in a better way. In recent years there have been various works related to this specialty and multiple data mining techniques derived from this to address different educational problems have been used. The aim of this paper is to present a review of the works in which data mining techniques were used to solve specific problems of education and to do a classification associated to diverse scenarios in which they have been applied.},
author = {{Villanueva Manjarres}, Andr{\'{e}}s and {Moreno Sandoval}, Luis Gabriel and {Salinas Su{\'{a}}rez}, Martha Janneth},
booktitle = {Digital Education Review},
language = {English},
title = {{Data Mining Techniques Applied in Educational Environments: Literature Review}},
year = {2018}
}
@misc{Klose2020,
abstract = {Imagine a student using an intelligent tutoring system. A researcher records the correctness and time of each of your attempts at solving a math problem, nothing more. With no names, no birth dates, no connections to the school, you would think it impossible to track the answers back to the class. Yet, class sections have been identified with no more data than this. This paper recounts shocking episodes where educational data was used to re-identify individual students, build profiles on students, and commit fraud. We look at the ethical principles that underlie privacy as it relates to research data, and discuss ethical issues in data mining relating to social networks and big data. We explore four major types of data used in EDM [educational data mining]: (i) clickstream data, (ii) student-interaction data, (iii) evaluative data, and (iv) demographic data. Each type of data can be harmful if disclosed in particular contexts, even if all personally identifiable information is removed. We consider laws and legal precedents controlling access to student data in the United States and the European Union. This paper concludes by describing some practical situations in EDM and suggesting privacy policies that satisfy the ethical concerns raised earlier in the paper. [For the full proceedings, see ED607784.]},
author = {Klose, Mark and Desai, Vasvi and Song, Yang and Gehringer, Edward},
booktitle = {International Educational Data Mining Society},
title = {{EDM and Privacy: Ethics and Legalities of Data Collection, Usage, and Storage}},
year = {2020}
}
@misc{Aguilar,
abstract = {We are still designing educational experiences for the "average" student, and have room to improve. Learning analytics provides a way forward. This commentary describes how learning analytics-based applications are well positioned to meaningfully personalize the learning experience in diverse ways. In so doing, learning analytics has the potential to contribute to more equitable and socially just educational outcomes for students who might otherwise be seen through the lens of the average student. Utilizing big data, good design, and the input of the stakeholders, learning analytics techniques aim to develop applications for the sole purpose of reducing the classroom size to 1. Over time, these digital innovations will enable us to do away with a model of education that teaches toward the non-existent average student, replacing it with one that is more socially just--one that addresses the individual needs of every student.},
author = {Aguilar, Stephen J},
booktitle = {TechTrends: Linking Research and Practice to Improve Learning},
language = {English},
number = {1},
pages = {37--45},
title = {{Learning Analytics: At the Nexus of Big Data, Digital Innovation, and Social Justice in Education}},
volume = {62}
}
@misc{Bezerra,
abstract = {In the current context of distance learning, learning management systems (LMSs) make it possible to store large volumes of data on web browsing and completed assignments. To understand student behavior patterns in this type of environment, educators and managers must rethink conventional approaches to the analysis of these data and use appropriate computational solutions, such as educational data mining (EDM). Previous studies have tested the application of EDM on small datasets. The main contribution of the present study is the application of EDM algorithms and the analysis of the results in a massive course delivered by a Brazilian University to 181,677 undergraduate students enrolled in different fields. The use of key algorithms in educational contexts, such as decision trees and clustering, can reveal relevant knowledge, including the attribute type that most significantly contributes to passing a course and the behavior patterns of groups of students who fail.},
author = {Bezerra, Luis Naito Mendes and Silva, M{\'{a}}rcia Terra},
booktitle = {International Journal of Distance Education Technologies},
language = {English},
number = {4},
pages = {17--30},
title = {{Educational Data Mining Applied to a Massive Course}},
volume = {18}
}
@misc{Lester2017,
abstract = {The purpose of this monograph is to give readers a practical and theoretical foundation in learning analytics in higher education, including an understanding of the challenges and incentives that are present in the institution, in the individual, and in the technologies themselves. Among questions that are explored and answered are: (1) What are the current trends in higher education that are driving a need for learning analytics tools?; (2) What role do institutional context, technological capacity, and individual beliefs play in promoting or constraining adoption and integration of learning analytics technologies in higher education?; (3) What are the ethical considerations related to use of learning analytics or other predictive data and associated interventions?; and (4) What are the practical implications and future research recommendations associated with learning analytics? This monograph draws from several areas of research--organizational theory, technology adoption, faculty beliefs and behaviors, and ethics and privacy--in a comprehensive model of learning analytics in higher education. This monograph is intended to serve as an introduction to learning analytics for those practitioners and researchers who are interested in learning more about the development, implementation, and promise of harnessing educational big data with predictive methods. Contents of this monograph include: (1) Executive Summary; (2) Acknowledgements; (3) Foreword; (4) Introduction to Learning Analytics and Educational Technology Tools in Higher Education; (5) How Organizational Context and Capacity and Technological Alignment Affect Learning Analytics Adoption; (6) Faculty, Advisor, and Student Decision Making Related to Use of Learning Analytics Data and Tools; (7) Ethical and Privacy Concepts and Considerations; and (8) Recommendations for Moving Forward: Considerations of Organizational Complexity, Data Fidelity, and Future Research.},
author = {Lester, Jaime and Klein, Carrie and Rangwala, Huzefa and Johri, Aditya},
booktitle = {ASHE Higher Education Report},
language = {English},
number = {5},
pages = {1--149},
title = {{Special Issue: Learning Analytics in Higher Education}},
volume = {43},
year = {2017}
}
@misc{Clayton,
abstract = {This article develops a perspective on big data in education, drawing on a broadly liberal conception of education's primary purpose. We focus especially on the rise of so-called learning analytics and the associated rise of digitization, which we evaluate according to the liberal view that education should seek to cultivate individuality and proceed partly by way of experimentation and with an emphasis on civic education. Our argument is not that the use of big data is wholly out of place in education. Indeed, it might have significant value in pursuit of certain educational aims. Nevertheless, the liberal conception shows how education is distinct from other domains in which big data are being applied, in ways that suggest that considerable caution must be exercised when they are used in educational contexts.},
author = {Clayton, Matthew and Halliday, Daniel},
booktitle = {Theory and Research in Education},
language = {English},
number = {3},
pages = {290--305},
title = {{Big Data and the Liberal Conception of Education}},
volume = {15}
}
@misc{Makela2016,
abstract = {"Big data" prompts a whole lexicon of terms--data flow; analytics; data mining; data science; smart you name it (cars, houses, cities, wearables, etc.); algorithms; learning analytics; predictive analytics; data aggregation; data dashboards; digital tracks; and big data brokers. New terms are being coined frequently. Are we paying attention to these? Do we know what they imply for us personally and professionally? Family and consumer sciences (FCS) is not exempt from this task nor unique in needing to understand the implications big data has for its profession and for those with whom FCS professionals work--students, clients, family members, employers, and for themselves. Professionals must recognize that they may be on the producing end (adding to the collection of big data)--tracking students' performance, monitoring financial behaviors, and shopping online. They will also be users of big data--seeking patterns in students' performance to provide interventions (learning analytics), issuing messages of reinforcement or reconsideration of financial transactions by clients (based on algorithms), and making online shopping choices with input from product reviews as to quality or satisfaction. The purpose of this article is to encourage thinking about the roles of FCS professionals--individually and collectively--in understanding the issues involved in the rapidly advancing collection of data for identified and yet-to-be-identified purposes. Some uses may be beneficial, some neutral, and some may threaten the well-being of individuals. We do not know or may not be able to imagine the unintended consequences of big data. Though many organizations have recording and archiving policies, we may not know the length of time our information is stored in a cloud; it may be far longer than the length of our actual lives.},
author = {Makela, Carole J},
booktitle = {Journal of Family and Consumer Sciences},
language = {English},
number = {2},
pages = {23--26},
title = {{Big Data: You Are Adding to . . . and Using It}},
volume = {108},
year = {2016}
}
@misc{Friedman,
abstract = {Learning analytics is an emerging field in which educators and researchers are using data to improve their students' educational experiences. One of the most common courses offered by higher academic institutions in the US is data science. This paper examines the data science syllabi found in today's academic sector and compares the results to those of Friedman's, "Technology, Pedagogy and Education," 26(5), 135-148 (2017) study of Big Data syllabi. For the present study, 40 data science syllabi used in private and public academic institutions in the US were collected, and Palmer et al.'s, "To Improve the Academy," 33, 14-36 (2014) rubric was used as a framework to analyze them. The study found that the most frequently used communication engagement tool, according to the syllabi, was discussion forums (used in 53{\%} of the syllabi), and instant message applications were second (21{\%}). Using Palmer et al.'s rubric, the study found 95{\%} of all data science syllabi the study examined provided very detailed articulation and scored in the top range outline by the model. In comparing data science syllabi to big data syllabi, the study found that data science syllabi provided better descriptions of the learning goals than did big data syllabi. Future studies could examine students' participation and appreciation of these courses using a machine analytics rubric.},
author = {Friedman, Alon},
booktitle = {Education and Information Technologies},
language = {English},
number = {6},
pages = {3467--3481},
title = {{Data Science Syllabi Measuring Its Content}},
volume = {24}
}
@misc{Asamoah,
abstract = {Within the context of the telecom industry, this teaching case is an active learning analytics exercise to help students build hands-on expertise on how to utilize Big Data to solve a business problem. Particularly, the case utilizes an analytics method to help develop a customer retention strategy to mitigate against an increasing customer churn problem in a telecom company. Traditionally, the forecast of customer churn uses various demographic and cell phone usage data. Big Data techniques permit a much finer granularity in the prediction of churn by analyzing specific activities a customer undertakes before churning. The authors help students to understand how data from customer interactions with the company through multiple channels can be combined to create a "session." Subsequently, the authors demonstrate the use of effective visualization to identify the most relevant paths to customer churn. The Teradata Aster Big Data platform is used in developing this case study.},
author = {Asamoah, Daniel A and Sharda, Ramesh and Kalgotra, Pankush and Ott, Mark},
booktitle = {Journal of Information Systems Education},
language = {English},
number = {4},
pages = {223--232},
title = {{"Teaching Case": Who Renews? Who Leaves? Identifying Customer Churn in a Telecom Company Using Big Data Techniques}},
volume = {27}
}
@misc{Heath2014,
abstract = {With the continued adoption of learning analytics in higher education institutions, vast volumes of data are generated and "big data" related issues, including privacy, emerge. Privacy is an ill-defined concept and subject to various interpretations and perspectives, including those of philosophers, lawyers, and information systems specialists. This paper provides an overview of privacy and considers the potential contribution contemporary privacy theories can make to learning analytics. Conclusions reflect on the suitability of these theories towards the advancement of learning analytics and future research considers the importance of hearing the student voice in this space.},
author = {Heath, Jennifer},
booktitle = {Journal of Learning Analytics},
language = {English},
number = {1},
pages = {140--149},
title = {{Contemporary Privacy Theory Contributions to Learning Analytics}},
volume = {1},
year = {2014}
}
@misc{Travis,
abstract = {Libraries remain one of the last places on campus where the purging of usage data is encouraged and "tracking" is a dirty word. While some libraries have demonstrated the usefulness of analytics, opponents bring up issues of privacy and debate the feasibility of student-generated library data for planning and assessment. Using a study conducted at the University Library, California State University, Long Beach, the authors of this article identified practical knowledge of data research that academic librarians will benefit from understanding. Readers will learn about the role campus culture plays in data gathering, be exposed to the complexities of learning analytics and Institutional Review Board (IRB) clearance, and read how the authors weighed the ethical use of big data analysis for assessing students.},
author = {Travis, Tiffini A and Ramirez, Christian},
booktitle = {portal: Libraries and the Academy},
language = {English},
number = {1},
pages = {33--47},
title = {{Big Data and Academic Libraries: The Quest for Informed Decision-Making}},
volume = {20}
}
@misc{Hoel2019,
abstract = {Purpose: Privacy is a culturally universal process; however, in the era of Big Data privacy is handled very differently in different parts of the world. This is a challenge when designing tools and approaches for the use of Educational Big Data (EBD) and learning analytics (LA) in a global market. The purpose of this paper is to explore the concept of information privacy in a cross-cultural setting to define a common point of reference for privacy engineering. Design/methodology/approach: The paper follows a conceptual exploration approach. Conceptual work on privacy in EBD and LA in China and the west is contrasted with the general discussion of privacy in a large corpus of literature and recent research. As much of the discourse on privacy has an American or European bias, intimate knowledge of Chinese education is used to test the concept of privacy and to drive the exploration of how information privacy is perceived in different cultural and educational settings. Findings: The findings indicate that there are problems using privacy concepts found in European and North-American theories to inform privacy engineering for a cross-cultural market in the era of Big Data. Theories based on individualism and ideas of control of private information do not capture current global digital practice. The paper discusses how a contextual and culture-aware understanding of privacy could be developed to inform privacy engineering without letting go of universally shared values. The paper concludes with questions that need further research to fully understand information privacy in education. Originality/value: As far as the authors know, this paper is the first attempt to discuss -- from a comparative and cross-cultural perspective -- information privacy in an educational context in the era of Big Data. The paper presents initial explorations of a problem that needs urgent attention if good intentions of privacy supportive educational technologies are to be turned into more than political slogans.},
author = {Hoel, Tore and Chen, Weiqin},
booktitle = {International Journal of Information and Learning Technology},
language = {English},
number = {4},
pages = {288--298},
title = {{Privacy Engineering for Learning Analytics in a Global Market: Defining a Point of Reference}},
volume = {36},
year = {2019}
}
@misc{Winne,
abstract = {A bottleneck in gathering big data about learning is instrumentation designed to record data about processes students use to learn and information on which those processes operate. The software system nStudy fills this gap. nStudy is an extension to the Chrome web browser plus a server side database for logged trace data plus peripheral modules that analyze trace data and assemble web pages as learning analytics. Students can use nStudy anywhere they connect to the internet. Every event related to creating, modifying, reviewing, linking and organizing information artifacts is logged in fine grain with a time stamp. These data fully trace information students operate on and how they operate on it. Ambient big data about studying gathered au naturel can be tailored by configuring several of nStudy's features. Thus the system can be used to gather data across a wide range lab studies and field trials designed to test a range of models and theories.},
author = {Winne, Philip H and Nesbit, John C and Popowich, Fred},
booktitle = {Technology, Knowledge and Learning},
language = {English},
number = {3},
pages = {369--376},
title = {{nStudy: A System for Researching Information Problem Solving}},
volume = {22}
}
@misc{Berg2016,
abstract = {This paper details the anticipated impact of synthetic "big" data on learning analytics (LA) infrastructures, with a particular focus on data governance, the acceleration of service development, and the benchmarking of predictive models. By reviewing two cases, one at the sector-wide level (the Jisc learning analytics architecture) and the other at the institutional level (the UvAInform learning analytics project at the University of Amsterdam), we explore the need for an on-demand tool for generating a wide range of synthetic data. We argue that the application of synthetic data will not only accelerate the creation of complex and layered learning analytics infrastructure, but will also help to address the ethical and privacy risks involved during service development.},
author = {Berg, Alan	M. and Mol, Stefan T and Kismih{\'{o}}k, G{\'{a}}bor and Sclater, Niall},
booktitle = {Journal of Learning Analytics},
language = {English},
number = {1},
pages = {107--128},
title = {{The Role of a Reference Synthetic Data Generator within the Field of Learning Analytics}},
volume = {3},
year = {2016}
}
@misc{Wilson2017,
abstract = {Learning analytic implementations are increasingly being included in learning management systems in higher education. We lay out some concerns with the way learning analytics--both data and algorithms--are often presented within an unproblematized Big Data discourse. We describe some potential problems with the often implicit assumptions about learning and learners--and indeed the tendency not to theorize learning explicitly--that underpin such implementations. Finally, we describe an attempt to devise our own analytics, grounded in a sociomaterial conception of learning. We use the data obtained to suggest that the relationships between learning and the digital traces left by participants in online learning are far from trivial, and that any analytics that relies on these as proxies for learning tends towards a behaviorist evaluation of learning processes.},
author = {Wilson, Anna and Watson, Cate and Thompson, Terrie Lynn and Drew, Valerie and Doyle, Sarah},
booktitle = {Teaching in Higher Education},
language = {English},
number = {8},
pages = {991--1007},
title = {{Learning Analytics: Challenges and Limitations}},
volume = {22},
year = {2017}
}
@misc{Scott,
abstract = {Recently, the possibilities for leveraging "big data" in research and pedagogy have given rise to the growing field of "learning analytics" in online education. While much of this work has focused on quantitative metrics, some have called for critical perspectives that interrogate such data as an interplay between technical infrastructures and contingent social practices. Following such calls, this article conceptualizes "learning analytics" as an assemblage of technical, designed, and sociocognitive dimensions. Drawing on DeLanda's articulation of assemblage theory, we examine the ways online learning unfolds within and across these scales by using illustrative quantitative and qualitative data--click-data, user-generated content, and student interviews--from three online higher education courses. We consider how insights generated from such a stance might contribute to critical perspectives on how power circulates in online learning environments--a framework we call "critical learning analytics." We conclude by offering some possibilities for which such a framework might be put to use--not only to map learning analytics as assemblage, but also to imagine how they might be assembled otherwise to promote more ethical instruction and more equitable student flourishing.},
author = {Scott, John and Nichols, T Philip},
booktitle = {Research in Education},
language = {English},
number = {1},
pages = {83--105},
title = {{Learning Analytics as Assemblage: Criticality and Contingency in Online Education}},
volume = {98}
}
@misc{Mkrttchian,
abstract = {Web-based learning has been developed by the majority of academic institutions and organizations worldwide due to its obvious benefits for both educators and learners. Meanwhile, many of the existing developmental approaches in this sphere lack one crucial consideration necessary for implementing web-based learning at academic institutions. In this article, the authors identify two processes: development of distance learning and digitalization of training that are represented now at almost every academic university. The article singles out the stages of their development and shows that the processes lead to the same result - a new quality of education. The authors focus on figuring out which path is more effective for achieving the highest level of development depending on university's characteristics. Accumulation of detailed information in the Electronic informational educational environment about current learning outcomes creates opportunities for emerging trends, such as Learning Analytics, Personalized Learning and Adaptive Learning. In data analysis using BigData and Machine Learning technologies.},
author = {Mkrttchian, Vardan and Krevskiy, Igor and Bershadsky, Alexander and Glotova, Tatiana and Gamidullaeva, Leyla and Vasin, Sergey},
booktitle = {International Journal of Web-Based Learning and Teaching Technologies},
language = {English},
number = {1},
pages = {32--53},
title = {{Web-Based Learning and Development of University's Electronic Informational Educational Environment}},
volume = {14}
}
@misc{Percell2016,
abstract = {Wikis continue to be used within technology environments of K-12 and higher education because they offer a collaborative environment for students to produce and receive content in concert with each other or on an individual basis (Kirkham, 2014). These online spaces are typically used as a course management system where students can both receive content from the instructor, as well as generate unique content on their own. Additionally, as wikis are digitally based platforms, that can generate a great amount of data that can be collected, collated, and analyzed. This article seeks to explore the practicality of the use of such big data sets arising from within course wikis from an instructional standpoint, and explores the data that practitioners may wish to capitalize upon so that big data and its associated learning analytics may inform instructional practices.},
author = {Percell, Jay C},
booktitle = {Quarterly Review of Distance Education},
language = {English},
number = {4},
pages = {63--71},
title = {{Data Collaborative: A Practical Exploration of Big Data in Course Wikis}},
volume = {17},
year = {2016}
}
@misc{Dringus,
abstract = {This essay is written to present a prospective stance on how learning analytics, as a core evaluative approach, must help instructors uncover the important trends and evidence of quality learner data in the online course. A critique is presented of strategic and tactical issues of learning analytics. The approach to the critique is taken through the lens of questioning the current status of applying learning analytics to online courses. The goal of the discussion is twofold: (1) to inform online learning practitioners (e.g., instructors and administrators) of the potential of learning analytics in online courses and (2) to broaden discussion in the research community about the advancement of learning analytics in online learning. In recognizing the full potential of formalizing big data in online courses, the community must address this issue also in the context of the potentially "harmful" application of learning analytics. (Contains 1 figure.)},
author = {Dringus, Laurie P},
booktitle = {Journal of Asynchronous Learning Networks},
language = {English},
number = {3},
pages = {87--100},
title = {{Learning Analytics Considered Harmful}},
volume = {16}
}
@misc{Lundie2017,
abstract = {The rise of learning analytics, the application of complex metrics developed to exploit the proliferation of "Big Data" in educational work, raises important moral questions about the nature of what is measurable in education. Teachers, schools and nations are increasingly held to account based on metrics, exacerbating the tendency for fine-grained measurement of learning experiences. In this article, the origins of learning analytics ontology are explored, drawing upon core ideas in the philosophy of computing, such as the general definition of information and the information-theoretic account of knowledge. Drawing upon a reading of Descartes "Meditatio II," which extends the phenomenology of Jean-Luc Marion into a pedagogy of intentionality, the article identifies a fundamental incompatibility between the subjective experience of learning and the information-theoretic account of knowledge. Human subjects experience and value their own information incommensurably with the ways in which computers measure and quantify information. The consequences of this finding for the design of online learning environments, and the necessary limitations of learning analytics and measurement are explored.},
author = {Lundie, David},
booktitle = {Educational Philosophy and Theory},
language = {English},
number = {4},
pages = {391--404},
title = {{The Givenness of the Human Learning Experience and Its Incompatibility with Information Analytics}},
volume = {49},
year = {2017}
}
@misc{Kuromiya,
abstract = {Evidence-based education has become more relevant in the current technology-enhanced teaching-learning era. This paper introduces how Educational BIG data has the potential to generate such evidence. As evidence-based education traditionally hooks on the meta-analysis of the literature, so there are existing platforms that support manual input of evidence as structured information. However, such platforms often focus on researchers as end-users and its design is not aligned to the practitioners' workflow. In our work, we propose a technology-mediated process of capturing teaching-learning cases (TLCs) using a learning analytics framework. Each case is primarily a single data point regarding the result of an intervention and multiple such cases would generate an evidence of intervention effectiveness. To capture TLCs in our current context, our system automatically conducts statistical modelling of learning logs captured from Learning Management Systems (LMS) and an e-book reader. Indicators from those learning logs are evaluated by the Linear Mixed Effects model to compute whether an intervention had a positive learning effect. We present two case studies to illustrate our approach of extracting case effectiveness from two different learning contexts -- one at a junior-high math class where email messages were sent as intervention and another in a blended learning context in a higher education physics class where an active learning strategy was implemented. Our novelty lies in the proposed automated approach of data aggregation, analysis, and case storing using a Learning Analytics framework for supporting evidence-based practice more accessible for practitioners.},
author = {Kuromiya, Hiroyuki and Majumdar, Rwitajit and Ogata, Hiroaki},
booktitle = {Educational Technology {\&} Society},
language = {English},
number = {4},
pages = {14--29},
title = {{Fostering Evidence-Based Education with Learning Analytics: Capturing Teaching-Learning Cases from Log Data}},
volume = {23}
}
@misc{Rienties2017,
abstract = {Most distance learning institutions collect vast amounts of learning data. Making sense of this 'Big Data' can be a challenge, in particular when data are stored at different data warehouses and require advanced statistical skills to interpret complex patterns of data. As a leading institute on learning analytics, the Open University UK instigated in 2012 a Data Wrangling initiative. This provided every Faculty with a dedicated academic with expertise data analysis and whose task is to provide strategic, pedagogical and sense-making advice to staff and senior management. Given substantial changes within the OU (e.g. new Faculty structure, real-time dashboards, two large-scale adoptions of predictive analytics approaches, increased reliance on analytics), this embedded case study provides an in-depth review of lessons learned of five years of data wrangling. We will elaborate on the design of the new structure, its strengths and potential weaknesses, and affordances to be adopted by other institutions.},
author = {Rienties, Bart and Cross, Simon and Marsh, Vicky and Ullmann, Thomas},
booktitle = {Open Learning},
language = {English},
number = {3},
pages = {279--293},
title = {{Making Sense of Learner and Learning Big Data: Reviewing Five Years of Data Wrangling at the Open University UK}},
volume = {32},
year = {2017}
}
@misc{Salles,
abstract = {During this digital era, France, like many other countries, is undergoing a transition from paper-based assessments to digital assessments in education. There is a rising interest in technology-enhanced items which offer innovative ways to assess traditional competencies, as well as addressing problem solving skills, specifically in mathematics. The rich log data captured by these items allows insight into how students approach the problem and their process strategies. Educational data mining is an emerging discipline developing methods suited for exploring the unique and increasingly large-scale data that come from such settings. Data-driven methods can be helpful when trying to make sense of process data. However, studies have shown that didactically meaningful findings are most likely generated when data mining techniques are guided by theoretical principles on subjects' skills. In this study, theoretical didactical grounding has been essential for developing and describing interactive mathematical tasks as well as defining and identifying strategic behaviors from the log data. Interactive instruments from France's national large-scale assessment in mathematics have been pilot tested in May 2017. Feature engineering and classical machine learning analysis were then applied to the process data of one specific technology-enhanced item. Supervised learning was implemented to determine the model's predictive power of students' achievement and estimate the weight of the variables in the prediction. Unsupervised learning aimed at clustering the samples. The obtained clusters are interpreted by the mean values of the important features. Both the analytical model and the clusters enable us to identify among students two conceptual approaches that can be interpreted in theoretically meaningful ways. If there are limitations to relying on log data analysis in order to determine learning profiles, one of them is the fact that this information remains partial when it comes to describing the complete cognitive activity at play, the potential of technology-enriched problem solving situations in large-scale assessments is nevertheless obvious. The type of findings this study produced is actionable from teachers' perspective in order to address students' specific needs.},
author = {Salles, Franck and {Dos Santos}, Reinaldo and Keskpaik, Saskia},
booktitle = {Large-scale Assessments in Education},
language = {English},
title = {{When Didactics Meet Data Science: Process Data Analysis in Large-Scale Mathematics Assessment in France}},
volume = {8}
}
@misc{Watson2017,
abstract = {In this paper, we present an in-depth case study of a single student who failed an online module which formed part of a master's programme in Professional Education and Leadership. We use this case study to examine assessment practices in higher education in the online environment. In taking this approach, we go against the current predilection for "Big Data" which has given rise to "learning analytics," a data-intensive approach to monitoring learning. In particular, we draw attention to the model of the learner produced by learning analytics and to issues of "dataveillance" in online learning. We also use the case to examine assessment in higher education more broadly, exploring the tensions between the requirements for certification and the need for learning. We conclude that assessment practices in higher education may have more to do with "quality assurance" and regulatory frameworks than with "enhancing the student experience" and inculcating the qualities that mark out higher education as an ethical project.},
author = {Watson, Cate and Wilson, Anna and Drew, Valerie and Thompson, Terrie Lynn},
booktitle = {Assessment {\&} Evaluation in Higher Education},
language = {English},
number = {7},
pages = {1030--1045},
title = {{Small Data, Online Learning and Assessment Practices in Higher Education: A Case Study of Failure?}},
volume = {42},
year = {2017}
}
@misc{Fynn,
abstract = {The prediction and classification of student performance has always been a central concern within higher education institutions. It is therefore natural for higher education institutions to harvest and analyse student data to inform decisions on education provision in resource constrained South African environments. One of the drivers for the use of learning and academic analytics is the pressures for greater accountability in the areas of improved learning outcomes and student success. Added to this is the pressure on local government to produce well-educated populace to participate in the economy. The counter discourse in the field of big data cautions against algocracy where algorithms takeover the human process of democratic decision making. Proponents of this view argue that we run the risk of creating institutions that are beholden to algorithms predicting student success but are unsure of how they work and are too afraid to ignore their guidance. This paper aims to discuss the ethics, values, and moral arguments revolving the use of big data using a practical demonstration of learning analytics applied at Unisa.},
author = {Fynn, Angelo},
booktitle = {International Review of Research in Open and Distributed Learning},
language = {English},
number = {6},
pages = {206--220},
title = {{Ethical Considerations in the Practical Application of the Unisa Socio-Critical Model of Student Success}},
volume = {17}
}
@misc{Roberts-Mahoney2016,
abstract = {Advanced by powerful venture philanthropies, educational technology companies, and the US Department of Education, a growing movement to apply "big data" through "learning analytics" to create "personalized learning" is currently underway in K-12 education in the United States. While scholars have offered various critiques of the corporate school reform agenda, the role of personalized learning technology in the corporatization of public education has not been extensively examined. Through a content analysis of United States Department of Education reports, personalized learning advocacy white papers, and published research monographs, this paper details how big data and adaptive learning systems are functioning to redefine educational policy, teaching, and learning in ways that transfer educational decisions from public school classrooms and teachers to private corporate spaces and authorities. The analysis shows that all three types of documents position education within a reductive set of economic rationalities that emphasize human capital development, the expansion of data-driven instruction and decision-making, and a narrow conception of learning as the acquisition of discrete skills and behavior modification detached from broader social contexts and culturally relevant forms of knowledge and inquiry. The paper concludes by drawing out the contradictions inherent to personalized learning technology and corporatization of schooling. It argues that these contradictions necessitate a broad rethinking of the value and purpose of new educational technology.},
author = {Roberts-Mahoney, Heather and Means, Alexander J and Garrison, Mark J},
booktitle = {Journal of Education Policy},
language = {English},
number = {4},
pages = {405--420},
title = {{Netflixing Human Capital Development: Personalized Learning Technology and the Corporatization of K-12 Education}},
volume = {31},
year = {2016}
}
@misc{Brinkhuis2018,
abstract = {With the advent of computers in education, and the ample availability of online learning and practice environments, enormous amounts of data on learning become available. The purpose of this paper is to present a decade of experience with analyzing and improving an online practice environment for math, which has thus far recorded over a billion responses. We present the methods we use to both steer and analyze this system in real-time, using scoring rules on accuracy and response times, a tailored rating system to provide both learners and items with current ability and difficulty ratings, and an adaptive engine that matches learners to items. Moreover, we explore the quality of fit by means of prediction accuracy and parallel item reliability. Limitations and pitfalls are discussed by diagnosing sources of misfit, like violations of unidimensionality and unforeseen dynamics. Finally, directions for development are discussed, including embedded learning analytics and a focus on online experimentation to evaluate both the system itself and the users' learning gains. Though many challenges remain open, we believe that large steps have been made in providing methods to efficiently manage and research educational big data from a massive online learning system.},
author = {Brinkhuis, Matthieu J S and Savi, Alexander O and Hofman, Abe D and Coomans, Frederik and van der Maas, Han L J and Maris, Gunter},
booktitle = {Journal of Learning Analytics},
language = {English},
number = {2},
pages = {29--46},
title = {{Learning as It Happens: A Decade of Analyzing and Shaping a Large-Scale Online Learning System}},
volume = {5},
year = {2018}
}
@misc{Shimada2019,
abstract = {In this paper, we focus on optimizing the assignment of students to courses. The target courses are conducted by different teachers using the same syllabus, course design, and lecture materials. More than 1,300 students are mechanically assigned to one of ten courses taught by different teachers. Therefore, mismatches often occur between students' learning behavior patterns and teachers' approach to teaching. As a result, students may be less satisfied, have a lower level of understanding of the material, and achieve less. To solve these problems, we propose a strategy to optimize the assignment of students to courses based on learning activity analytics. The contributions of this study are 1) clarifying the relationship between learning behavior pattern and teaching based on learning activity analytics using large-scale educational data, 2) optimizing the assignment of students to courses based on learning behavior pattern analytics, and 3) demonstrating the effectiveness of assignment optimization via simulation experiments. [For the full proceedings, see ED599096.]},
author = {Shimada, Atsushi and Mouri, Kousuke and Taniguchi, Yuta and Ogata, Hiroaki and Taniguchi, Rin-ichiro and Konomi, Shin'ichi},
booktitle = {International Educational Data Mining Society},
title = {{Optimizing Assignment of Students to Courses Based on Learning Activity Analytics}},
year = {2019}
}
@misc{Rambe,
abstract = {Challenges of broadening access, escalating cost, maintaining desirable quality and enhancing meaningful learning experiences in African higher education (HE) have spurred debates on how to restructure higher education delivery to meet the diverse needs of heterogeneous learners and adapt pedagogical models to the educational realities of low-income African countries. In view of these complexities, Massive Open Online Courses (MOOCs) have been advanced by Western Consortia, universities and online platform providers as panaceas for disrupting/transforming existing education models African universities. MOOCs have been touted as disruptive innovations with the potential to create new niche markets for HE courses, disrupt traditional models of instruction and content delivery and create new revenue streams for higher education. Yet academic elitism which manifests in the exclusive selection of top American universities to develop, host and deliver MOOCs, MOOC providers' use of university brand and reputation as benchmarks for charging recruitment fees on headhunters recruiting MOOC graduates and their complex business models involving the sale of students' big data (e.g. learning analytics) for profit seem to be inconsistent with claims about philanthropic and egalitarian drive of MOOCs. Drawing on disruptive innovation theory and a review of mainstream literature on MOOCs adoption in American and African tertiary sectors, this study argues that behind the MOOC rhetoric of disrupting and democratizing higher education lies the projection of top academic brands on the marketing pedestal, financial piggybacking on the hype and politics of academic exclusion.},
author = {Rambe, Patient and Moeti, Mamello},
booktitle = {Educational Technology Research and Development},
language = {English},
number = {3},
pages = {631--651},
title = {{Disrupting and Democratising Higher Education Provision or Entrenching Academic Elitism: Towards a Model of MOOCs Adoption at African Universities}},
volume = {65}
}
@misc{Ostrow2017,
abstract = {Data	is flexible in that it is molded by not only the features and variables available to a researcher for analysis and interpretation, but also by how those features and variables are recorded and processed prior to evaluation. "Big Data" from online learning platforms and intelligent tutoring systems is no different. The work presented herein questions the quality and flexibility of data from two popular learning platforms, comparing binary measures of problem-level accuracy, the scoring method typically used to inform learner analytics, with partial credit scoring, a more robust, real-world methodology. This work extends previous research by examining how the manipulation of scoring methodology has the potential to alter outcomes when testing hypotheses, or specifically, when looking for significant differences between groups of students. Datasets from ASSISTments and Cognitive Tutor are used to assess the implications of data availability and manipulation within twelve mathematics skills. A resampling approach is used to determine the size of equivalent samples of high- and low-performing students required to reliably differentiate performance when considering each scoring methodology. Results suggest that in eleven out of twelve observed skills, partial credit offers more efficient group differentiation, increasing analytic power and reducing Type II error. Alternative applications of this approach and implications for the Learning Analytics community are discussed. [Federal funding was received from the Graduate Assistance in Areas of National Need (GAANN) program, Student Service, Higher Education Programs, Office of Postsecondary Education.]},
author = {Ostrow, Korinn S and Wang, Yan and Heffernan, Neil T},
booktitle = {Journal of Learning Analytics},
language = {English},
number = {2},
pages = {91--112},
title = {{How Flexible Is Your Data? A Comparative Analysis of Scoring Methodologies across Learning Platforms in the Context of Group Differentiation}},
volume = {4},
year = {2017}
}
@misc{Martin-Monje2018,
abstract = {Data mining is increasing its popularity in the research of Technology-Enhanced Language Learning and Applied Linguistics in general. It enables a better understanding of progress, performance and possible pitfalls, which would be useful for language learners, teachers and researchers. Until recently it was an unexplored field, but it is expected to grow exponentially in the following years. This article attempts to be a relevant contribution as an instance of empirical research, showing the application of Learning Analytics to the Language MOOC (LMOOC) 'How to succeed in the English B1 Level Exam.' The focus or the research was threefold, trying to find out: (1) what types of learning objects students engage with most, (2) what aspects of online interaction relate more strongly to course completion and success, and (3) which are the most prominent student profiles in an LMOOC. Results show that short video-pills are the most powerful learning objects in this type of online courses, the regular submission of automated grading activities is a robust indicator towards course success, and the most prominent student profile in LMOOCs is 'viewers', those who access the learning materials but do not submit tasks or engage in online interaction actively, which would explain why the completion rate in LMOOCs is so low. This novel perspective into students' language learning, which big data has assisted us in, should guide course creators to re-design the LMOOC for the enhancement of the audio-visual content. LMOOC instructors and facilitators should also encourage participants to increase the submission of activities--acknowledging these small achievements through micro-credentialing and badges-, and special attention ought to be paid to the most prominent LMOOC profile, those 'viewers' who should be lured into becoming 'solvers' or, even better, 'all-rounders'.},
author = {Mart{\'{i}}n-Monje, Elena and Castrillo, Mar{\'{i}}a Dolores and Ma{\~{n}}ana-Rodr{\'{i}}guez, Jorge},
booktitle = {Computer Assisted Language Learning},
language = {English},
number = {3},
pages = {251--272},
title = {{Understanding Online Interaction in Language MOOCs through Learning Analytics}},
volume = {31},
year = {2018}
}
@misc{Timmis,
abstract = {While it is frequently argued that assessment sits at the heart of the learning process, in practice assessment often remains narrowly focused on qualifications and reporting achievements, driven by institutional and societal aspirations and tensions such as accountability and economic well being. Yet, the need for assessment to account for the knowledge, skills, dispositions and attitudes necessary to equip young people for a changing and increasingly digital world is also increasingly acknowledged. Based on our recent research review, this article critically examines the role of technology enhanced assessment (or TEA). We argue that while technology offers many potentially creative opportunities for innovation and for rethinking assessment purposes, there are also numerous risks and challenges. In particular we highlight ethical concerns over social exclusion and new forms of digital dividedness and the increasing risks associated with big data and the rise of learning analytics. Finally, we note that much research and innovation happens in silos, where policy, research and practice on assessment, technology enhanced assessment and ethical and political concerns are not linked up. We conclude that there needs to be a much more wide-ranging, critical and nuanced discussion in educational and policy circles so that debates about the potential of technology can be linked to improving assessment in the light of the range of social and political challenges that such progress presents. We end with some critical questions for policy, practice and research communities, which we offer as a starting point for future thinking and ways forward.},
author = {Timmis, Sue and Broadfoot, Patricia and Sutherland, Rosamund and Oldfield, Alison},
booktitle = {British Educational Research Journal},
language = {English},
number = {3},
pages = {454--476},
title = {{Rethinking Assessment in a Digital Age: Opportunities, Challenges and Risks}},
volume = {42}
}
@misc{Scandura2013,
abstract = {This article begins with a summary of two dominant approaches to adaptive learning systems: Intelligent Tutoring Systems (ITS), which have been around since the late 1970s and relatively new learning systems based on Learning Analytics, deriving largely from technical advances in BIG DATA pioneered by Google. The article then describes a third approach deriving from a long history of basic research in structural learning. TutorIT is a dynamically adaptive tutoring (not just adaptive learning) system that interacts with students based on what they do and do not know at each point in time -- as might a good human tutor. AuthorIT is an authoring platform that makes it possible for subject matters experts and instructional designers (SMEs) to create dynamically adaptive tutors in their own areas of expertise.},
author = {Scandura, Joseph M},
booktitle = {Technology, Instruction, Cognition and Learning},
language = {English},
number = {3},
pages = {137--145},
title = {{Introduction to Dynamically Adaptive Tutoring: AuthorIT Authoring and TutorIT Delivery Systems}},
volume = {9},
year = {2013}
}
@misc{Wise2015,
abstract = {It is an exhilarating and important time for conducting research on learning, with unprecedented quantities of data available. There is a danger, however, in thinking that with enough data, the numbers speak for themselves. In fact, with larger amounts of data, theory plays an ever-more critical role in analysis. In this introduction to the special section on learning analytics and learning theory, we describe some critical problems in the analysis of large-scale data that occur when theory is not involved. These questions revolve around what variables a researcher should attend to and how to interpret a multitude of micro-results and make them actionable. We conclude our comments with a discussion of how the collection of empirical papers included in the special section, and the commentaries that were invited on them, speak to these challenges, and in doing so represent important steps towards theory-informed and theory-contributing learning analytics work. Our ultimate goal is to provoke a critical dialogue in the field about the ways in which learning analytics research draws on and contributes to theory.},
author = {Wise, Alyssa Friend and Shaffer, David Williamson},
booktitle = {Journal of Learning Analytics},
language = {English},
number = {2},
pages = {5--13},
title = {{Why Theory Matters More than Ever in the Age of Big Data}},
volume = {2},
year = {2015}
}
@misc{Godwin-Jones,
abstract = {From its earliest days, practitioners of computer-assisted language learning (CALL) have collected data from computer-mediated learning environments. Indeed, that has been a central aspect of the field from the beginning. Usage logs provided valuable insights into how systems were used and how effective they were for language learning. That information could be analyzed to improve instructional design and delivery. Maintaining learning histories and personal profiles of individual learners enabled a program to adapt the delivery of learning materials to the record of student performance. Given a limited number of users working within a single system, the data generated could be collected and analyzed easily, using simple methods and tools such as spreadsheets and basic data models. The situation today is quite different from that scenario. Learners are likely to be using multiple online tools and services, all of which may be recording data. That includes general use software and services such as Facebook and Google, as well as mobile devices. If they are university students, they are likely to be generating data points through a learning management system (LMS) as well as from other university-level systems. The vast amount of information collected today from our use of online tools and services provides a huge storehouse of information that can be mined to provide both general usage trends and individualized reports. This "big data" offers valuable teaching and learning insights. In this column, we will be looking at what this may mean in language learning. That will include discussion of the emerging field of learning analytics, the use of learner models, and the opportunities afforded by data tracking for personalized learning.},
author = {Godwin-Jones, Robert},
booktitle = {Language Learning {\&} Technology},
language = {English},
number = {1},
pages = {4--15},
title = {{Scaling Up and Zooming In: Big Data and Personalization in Language Learning}},
volume = {21}
}
@misc{Ibanez,
abstract = {The main objective of educational institutions is to achieve the integral development of their students in their learning and knowledge construction process. One way to achieve these objectives is the accompaniment and continuous monitoring of students in this process, adapting the methods to their training needs. In online and mixed teaching modalities (eLearning methodology), this monitoring is carried out through the digital platforms in which it is carried out in the academic activity, such as the learning management system platforms. These virtual teaching and learning environments (EVA) allow access to learners' fingerprints, generating a large volume of data, that analysis allows a deep way of their behavior in those policies. This article collects the results of the exploration of student activity in the virtual campus (Blackboard Learn), which is in the first phase of Learning Analytics project carried out by the Nebrija University and discusses its implications for educational institutions. The data extracted correspond to the 2016-2017 course and have been analyzed around four blocks of information: user behavior, user activity, activity in the content areas and activity in the forums.},
author = {Iba{\~{n}}ez, Patricia and Villalonga, Cristina and Nuere, Leire},
booktitle = {Technology, Knowledge and Learning},
language = {English},
number = {4},
pages = {769--787},
title = {{Exploring Student Activity with Learning Analytics in the Digital Environments of the Nebrija University}},
volume = {25}
}
@misc{Dyckhoff2012,
abstract = {Learning Analytics can provide powerful tools for teachers in order to support them in the iterative process of improving the effectiveness of their courses and to collaterally enhance their students' performance. In this paper, we present the theoretical background, design, implementation, and evaluation details of eLAT, a Learning Analytics Toolkit, which enables teachers to explore and correlate learning object usage, user properties, user behavior, as well as assessment results based on graphical indicators. The primary aim of the development of eLAT is to process large data sets in microseconds with regard to individual data analysis interests of teachers and data privacy issues, in order to help them to self-reflect on their technology-enhanced teaching and learning scenarios and to identify opportunities for interventions and improvements. (Contains 9 figures.)},
author = {Dyckhoff, Anna Lea and Zielke, Dennis and Bultmann, Mareike and Chatti, Mohamed Amine and Schroeder, Ulrik},
booktitle = {Educational Technology {\&} Society},
language = {English},
number = {3},
pages = {58--76},
title = {{Design and Implementation of a Learning Analytics Toolkit for Teachers}},
volume = {15},
year = {2012}
}
@misc{Monroy2014,
abstract = {In this paper, we discuss a scalable approach for integrating learning analytics into an online K-12 science curriculum. A description of the curriculum and the underlying pedagogical framework is followed by a discussion of the challenges to be tackled as part of this integration. We include examples of data visualization based on teacher usage data along with a methodology for examining an inquiry-based science program. With more than one million students and fifty thousand teachers using the curriculum, a massive and rich dataset is continuously updated. This repository depicts teacher and student usage, and offers exciting opportunities to leverage data to improve both teaching and learning. In this paper, we use data from a medium-sized school district, comprising 53 schools, 1,026 teachers, and nearly one-third of a million curriculum visits during the 2012-2013 school year. This growing dataset also poses technical challenges such as data storage, complex aggregation, and analyses with broader implications for pedagogy, big data, and learning.},
author = {Monroy, Carlos and Rangel, Virginia Snodgrass and Whitaker, Reid},
booktitle = {Journal of Learning Analytics},
language = {English},
number = {2},
pages = {94--125},
title = {{A Strategy for Incorporating Learning Analytics into the Design and Evaluation of a K-12 Science Curriculum}},
volume = {1},
year = {2014}
}
@misc{Moore2019,
abstract = {Learning analytics focuses on extracting meaning from large amounts of data. One of the largest datasets in education comes from Massive Open Online Courses (MOOCs) that typically feature enrollments in the tens of thousands. Analyzing MOOC discussion forums presents logistical issues, resulting chiefly from the size of the dataset, which can create challenges for understanding and adequately describing student behaviors. Utilizing automatic text analysis, this study built a hierarchical linear model that examines the influence of the pacing condition of a massive open online course (MOOC), whether it is self-paced or instructor-paced, on the demonstration of cognitive processing in a HarvardX MOOC. The analysis of 2,423 discussion posts generated by 671 students revealed the number of dictionary words used were positively associated with cognitive processing while analytical thinking and clout was negatively associated. We found that none of the student background information (gender, education), status of the course engagement (explored or completed), or the course pace (self-paced versus instructor paced) significantly influenced the cognitive processing of the postings.},
author = {Moore, Robert L and Oliver, Kevin M and Wang, Chuang},
booktitle = {Interactive Learning Environments},
language = {English},
pages = {655--669},
title = {{Setting the Pace: Examining Cognitive Processing in MOOC Discussion Forums with Automatic Text Analysis}},
volume = {27},
year = {2019}
}
@misc{Kovanovic2015,
abstract = {With	widespread adoption of Learning Management Systems (LMS) and other learning technology, large amounts of data--commonly known as trace data--are readily accessible to researchers. Trace data has been extensively used to calculate time that students spend on different learning activities--typically referred to as time-on-task. These measures are used to build predictive models of student learning in order to understand and improve learning processes. While time-on-task measures have been used in Learning Analytics research, the consequences of their use are not fully described or examined. This paper presents findings from two	experiments regarding different time-on-task estimation methods and their influence on research findings. Based on modelling different student performance measures with popular statistical methods in two datasets (one online, one blended), our findings indicate that time-on-task estimation methods play an important role in shaping the final study results, particularly in online settings where the amount of interaction with LMS is typically higher. The primary goal of this paper is to raise awareness and initiate debate on the important issue of time-on-task estimation within the broader learning analytics community. Finally, the paper provides an overview of commonly adopted time-on-task estimation methods in educational and related research fields.},
author = {Kovanovic, Vitomir and Ga{\v{s}}evic, Dragan and Dawson, Shane and Joksimovic, Srecko and Baker, Ryan S and Hatala, Marek},
booktitle = {Journal of Learning Analytics},
language = {English},
number = {3},
pages = {81--116},
title = {{Does Time-on-Task Estimation Matter? Implications for the Validity of Learning Analytics Findings}},
volume = {2},
year = {2015}
}
@misc{Culatta,
abstract = {Education in the United States is entering a very exciting moment. For the first time, all of the digital stars are aligning n such a way that the technology is available to design truly transformational learning experiences. The ubiquity of inexpensive and powerful mobile devices is creating the potential for all students to learn at any time and in any location. Increased wired and wireless broadband is creating the potential for learners to engage and interact with peers and experts around the world. A proliferation of data from digital learning activities is creating the potential to leverage "big data" and learning analytics for personalizing learning. All of these elements are combining to create the potential for this to become education's Internet moment. To take advantage of the energizing technological promise to improve learning, one needs to determine how to accelerate the rate at which new learning tools and techniques are developed and implemented. By accelerating the pace of innovation in educational technology, one will have the opportunity to close the achievement gap, improve national competitiveness, and drive economic growth. (Contains 2 figures and 8 notes.)},
author = {Culatta, Richard},
booktitle = {EDUCAUSE Review},
language = {English},
number = {6},
pages = {24},
title = {{From Innovation Clusters to Datapalooza: Accelerating Innovation in Educational Technology}},
volume = {47}
}
@misc{Park2017,
abstract = {As the advance of learning technologies and analytics tools continues, learning management systems (LMSs) have been required to fulfil the growing expectations for smart learning. However, the reality regarding the level of technology integration in higher education differs considerably from such expectations or the speed of advances in educational technologies. This research aimed to evaluate the current activation levels and usage patterns of a LMS. A large data-set was analysed, which included the online activity information from 7940 courses. Through data pre-processing, "general indicators" reflecting login frequencies of the virtual campus and "activity-based indicators" presenting the activation patterns of diverse functions provided by Moodle were derived. Activity theory was applied to interpret the results of analysis, since it has been recognised as a powerful framework to understand phenomena encompassing interactive systems. Further, time-series investigation over three consecutive semesters allowed observation of historical changes. The results revealed considerably low use of the virtual campus with only slight changes, as well as significantly different activity patterns across course attributes and colleges. Contradictions among components in the activity system are discussed, along with the implications for improving teaching and learning with LMS in higher education.},
author = {Park, Yeonjeong and Jo, Il-Hyun},
booktitle = {Assessment {\&} Evaluation in Higher Education},
language = {English},
number = {4},
pages = {531--547},
title = {{Using Log Variables in a Learning Management System to Evaluate Learning Activity Using the Lens of Activity Theory}},
volume = {42},
year = {2017}
}
